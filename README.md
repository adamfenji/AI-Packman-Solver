## ðŸ“˜ Project Overview

This repository documents my work from **CS4811: Artificial Intelligence**, a core upper-level computer science course I completed at **Michigan Technological University**. The class adapted materials and project infrastructure from UC Berkeleyâ€™s **CS188: Artificial Intelligence**. The course introduces foundational concepts in artificial intelligence, including state-space search, adversarial reasoning, constraint satisfaction, logical inference, probabilistic reasoning, and machine learning. The class is hands-on and project-heavy, with each project focusing on a major subarea of AI using the Pac-Man autograder environment.

[https://tenor.com/view/old-school-video-games-pac-man-gif-12836291](https://tenor.com/view/old-school-video-games-pac-man-gif-12836291)

## ðŸ“‚ AI Topics & Techniques Implemented

| # | Topic                        | Description |
|---|-----------------------------|-------------|
| 1 | [Search](Project%201_%20Search.html)                  | Implemented DFS, BFS, UCS, and A* search to navigate mazes and collect food |
| 2 | [Adversarial Search](Project%202_%20Adversarial%20Search.html)     | Developed agents using Minimax, Alpha-Beta pruning, and Expectimax strategies |
| 3 | [Logic](Project%203_%20Logic.html)                   | Encoded knowledge in propositional logic and used SAT solvers for Clue and planning problems |
| 4 | [Probabilistic Inference](Project%204_%20Ghostbusters.html)           | Applied probabilistic inference and particle filtering to locate hidden ghosts |
| 5 | [Reinforcement Learning](Project%205_%20Reinforcement%20Learning.html) | Trained Q-learning agents to learn optimal policies via reward feedback |
| 6 | [Machine Learning](Project%206_%20Machine%20Learning.html)       | Built Naive Bayes classifiers and neural networks for digit and language classification |

## Final Outcome & Project Integration

Together, these projects simulate the construction of an intelligent autonomous agent (Pac-Man Solver) capable of:

- **Planning its path** through unknown environments using optimal search algorithms
- **Competing and cooperating** in multi-agent scenarios using strategic reasoning
- **Making decisions under uncertainty** using probabilistic models and sensory input
- **Learning from experience** via reinforcement learning without a model of the world
- **Recognizing patterns** and **making predictions** with machine learning models

By the end of the course, the combination of these components reflects how modern AI systems integrate **search**, **logic**, **probability**, and **learning** to operate in dynamic, partially observable, and adversarial environments.

## ðŸ§  Key Learnings

- Mastered foundational AI techniques such as **state-space search**, **game trees**, and **logical inference**
- Applied **probabilistic models** like Bayes Nets and Hidden Markov Models to track uncertainty
- Implemented **Q-learning algorithms** to teach agents how to act under delayed reward signals
- Constructed **neural networks from scratch**, exploring backpropagation and non-linear modeling
- Used real-world applications like **digit recognition** and **language identification** to evaluate ML models
- Built modular, testable AI systems using **Python**, **NumPy**, and custom autograders
- Practiced **experimental tuning** of hyperparameters and policies in reinforcement learning and machine learning setups
- Learned to think algorithmically under conditions of **incomplete information** and **strategic interaction**

## ðŸ”— References

- [CS4811 Course Page @ MTU](https://pages.mtu.edu/~lebrown/cs4811-f23/web/)
- [CS188 Course Page @ UC Berkeley](https://inst.eecs.berkeley.edu/~cs188/fa23/)
